{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_csv.ipynb\n",
    "\n",
    "## Description\n",
    "This jupyter notebook creates a csv file based on the directory you want to finetune.\n",
    "Specifically, this code will take the file and create train, val, and test splits for your directory.\n",
    "The csv file will be placed in the preceding directory. It is important to run this for your dataloader. The csv file will be the same name as the directory. The random split probabilities will most accurate as number of samples increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: CODE TO CHANGE HERE ##\n",
    "\n",
    "# Example data here is mammogram data for training\n",
    "DATA_PATH = os.path.abspath(\"../medvae/data/mmg_data\")\n",
    "\n",
    "train_pct = 0.6\n",
    "val_pct = 0.2\n",
    "test_pct = 0.2\n",
    "\n",
    "# Create a list of probabilities\n",
    "probabilities = [train_pct, val_pct, test_pct]\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Make sure the sum of the percentages is 1\n",
    "assert sum(probabilities) == 1\n",
    "\n",
    "# Make sure splits == pcts\n",
    "assert len(splits) == len(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 7588.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate \n",
    "data_files = os.listdir(DATA_PATH) \n",
    "\n",
    "# Shuffle the data files\n",
    "random.seed(42)\n",
    "random.shuffle(data_files)\n",
    "\n",
    "save_df = []\n",
    "\n",
    "# Iterate through all the files in the data directory\n",
    "for i, data_file in tqdm(enumerate(data_files), total=len(data_files)):\n",
    "    file_id = data_file.split('.')[0]\n",
    "    \n",
    "    save_df.append({\n",
    "        'row_nr': i,\n",
    "        'image_uuid': file_id,\n",
    "        # Randomly assign the split, with 60% train, 20% val, 20% test\n",
    "        'split': np.random.choice(splits, p=probabilities)\n",
    "    })\n",
    "\n",
    "# Create a pandas DataFrame from the save_df list\n",
    "save_df = pd.DataFrame(save_df)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "save_df.to_csv(os.path.join('/'.join(DATA_PATH.split('/')[:-1]), f'{DATA_PATH.split(\"/\")[-1]}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
